{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x12f85e390>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x12f8198b0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Varsha! Congratulations on being a Chief AI Engineer, that's a very impressive title. Can you tell me more about your work and what you do in that role? Are you working on any exciting projects or advancements in AI right now?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 49, 'total_tokens': 103, 'completion_time': 0.094146952, 'completion_tokens_details': None, 'prompt_time': 0.010039641, 'prompt_tokens_details': None, 'queue_time': 0.007150833, 'total_time': 0.104186593}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e2c608b1d6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c8e0d-e9aa-7c30-9526-363455192fde-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 49, 'output_tokens': 54, 'total_tokens': 103})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My Name is Varsha and I am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Varsha, and you are a Chief AI Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 118, 'total_tokens': 133, 'completion_time': 0.020332855, 'completion_tokens_details': None, 'prompt_time': 0.006803035, 'prompt_tokens_details': None, 'queue_time': 0.005749609, 'total_time': 0.02713589}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_66c49b4aa6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c8e0d-ec34-7d53-8326-8502b390f2f3-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 118, 'output_tokens': 15, 'total_tokens': 133})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi , My Name is Varsha and I am a Chief AI Engineer\"),\n",
    "    AIMessage(content=\"Nice to meet you, Varsha. As a Chief AI Engineer, that's a fascinating role. What areas of AI are you currently working on or have expertise in?Are you involved in any exciting projects or innovations in the field? \")\n",
    ",    HumanMessage(content=\"What's my name and what do I do? \")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Nice to meet you, Varsha. How can I assist you today?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 42, 'total_tokens': 58, 'completion_time': 0.027449857, 'completion_tokens_details': None, 'prompt_time': 0.002537817, 'prompt_tokens_details': None, 'queue_time': 0.005528919, 'total_time': 0.029987674}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d317489708', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c8e0d-f36c-7e53-9109-e058da5ec499-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 42, 'output_tokens': 16, 'total_tokens': 58}\n",
      "content=\"I don't have any information about your name. I'm a large language model, I don't have the ability to retain information about individual users or recall previous conversations. Each time you interact with me, it's a new conversation. If you'd like to share your name, I'd be happy to chat with you!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 40, 'total_tokens': 106, 'completion_time': 0.069555041, 'completion_tokens_details': None, 'prompt_time': 0.001901568, 'prompt_tokens_details': None, 'queue_time': 0.00546441, 'total_time': 0.071456609}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8f8420ecd7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c8e0d-f3d9-7ba2-a4f0-e2f302181847-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 40, 'output_tokens': 66, 'total_tokens': 106}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Session 1\n",
    "response1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is Varsha\")],\n",
    "    config={\"session_id\": \"chat1\"}\n",
    ")\n",
    "print(response1)\n",
    "\n",
    "# Session 2\n",
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config={\"session_id\": \"chat2\"}\n",
    ")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My Name is Varsha and I am a Chief AI Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Impressive, Varsha! As a Chief AI Engineer, you must be at the forefront of cutting-edge technology. I'm excited to learn more about your work and experiences. What specific areas of AI are you currently working on or interested in?\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Varsha, and you're a Chief AI Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 144, 'total_tokens': 159, 'completion_time': 0.020888533, 'completion_tokens_details': None, 'prompt_time': 0.009773207, 'prompt_tokens_details': None, 'queue_time': 0.005055417, 'total_time': 0.03066174}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_020e283281', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c8e0d-fd2f-7071-80e2-419cfcaa5f08-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 144, 'output_tokens': 15, 'total_tokens': 159})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content=\"What's my name\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunnableWithMessageHistory' object has no attribute 'reset_memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#change the config\u001b[39;00m\n\u001b[32m      2\u001b[39m config1={\u001b[33m\"\u001b[39m\u001b[33mConfigurable\u001b[39m\u001b[33m\"\u001b[39m:{\u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mchat4\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mwith_message_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset_memory\u001b[49m(session_id=\u001b[33m\"\u001b[39m\u001b[33mchat4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m response=with_message_history.invoke([\n\u001b[32m      5\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mWhat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms my name\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m      6\u001b[39m     config=config1\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Virtual_Environments/Chatbot_env/lib/python3.12/site-packages/pydantic/main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunnableWithMessageHistory' object has no attribute 'reset_memory'"
     ]
    }
   ],
   "source": [
    "#change the config\n",
    "config1={\"Configurable\":{\"session_id\":\"chat4\"}}\n",
    "with_message_history.reset_memory(session_id=\"chat4\")\n",
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content=\"What's my name\")],\n",
    "    config=config1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Impressive, Varsha! As a Chief AI Engineer, you must be at the forefront of cutting-edge technology. I'm excited to learn more about your work and experiences. What specific areas of AI are you currently working on or interested in?\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat1: Nice to meet you, Varsha! It's great to connect with a Chief AI Engineer. What brings you here today? Are you looking to discuss a specific AI-related topic, seeking advice, or exploring new ideas? I'm all ears!\n",
      "Chat2: I don't have any information about your name. I'm a large language model, I don't have the ability to retain information about individual users or recall previous conversations. Each time you interact with me, it's a new conversation and I don't have any context or knowledge about you. If you'd like to share your name, I'd be happy to chat with you!\n"
     ]
    }
   ],
   "source": [
    "model1 = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=groq_api_key)\n",
    "chat1 = model1  # or wrap in your chain if needed\n",
    "response1 = chat1.invoke([HumanMessage(content=\"Hi, My Name is Varsha and I am a Chief AI Engineer\")])\n",
    "print(\"Chat1:\", response1.content)\n",
    "\n",
    "# Chat 2 - completely independent\n",
    "model2 = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=groq_api_key)\n",
    "chat2 = model2\n",
    "response2 = chat2.invoke([HumanMessage(content=\"What's my name?\")])\n",
    "print(\"Chat2:\", response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Prompt Tempaltes\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Hey,You are a helpful assistant, Answer all the questions to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "])\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Krish. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73, 'completion_time': 0.020444254, 'completion_tokens_details': None, 'prompt_time': 0.004795858, 'prompt_tokens_details': None, 'queue_time': 0.006031202, 'total_time': 0.025240112}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8f8420ecd7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c8e0e-0a0c-7c42-96dd-a5c601d958ec-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Krish\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Krish! I'm happy to help with any questions or topics you'd like to discuss. What's on your mind today?\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hi My name is Krish\")],\n",
    "    config=config3)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add more complexity\n",
    "prompt1=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Hey,You are a helpful assistant, Answer all the questions to the best of your ability in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "])\n",
    "\n",
    "chain1=prompt1|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain1.invoke({\"messages\":[HumanMessage(content=\"Hi I am Jyothi\")],\"language\": \"telugu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'హై జ్యోతి, నిమ్మతడానికి ఉందా నా సహాయంలో ఉంటాను. ఏమి తెలుసుకోవాలి?'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain1,get_session_history,input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "config4={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते ज्योति! मैं आपकी सहायता करने के लिए यहाँ हूँ। क्या आपके पास कोई सवाल या किसी चीज़ के बारे में जानकारी चाहिए?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 62, 'total_tokens': 125, 'completion_time': 0.088926644, 'completion_tokens_details': None, 'prompt_time': 0.003654314, 'prompt_tokens_details': None, 'queue_time': 0.005733158, 'total_time': 0.092580958}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d317489708', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c8e0e-1dd6-7a42-9565-585341c9391d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 62, 'output_tokens': 63, 'total_tokens': 125})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({'messages':[HumanMessage(content=\"Hi I am Jyothi\")],\"language\":\"Hindi\"},\n",
    "                            config=config4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आपका नाम ज्योति है।', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 139, 'total_tokens': 151, 'completion_time': 0.015374376, 'completion_tokens_details': None, 'prompt_time': 0.008115071, 'prompt_tokens_details': None, 'queue_time': 0.005481394, 'total_time': 0.023489447}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_66c49b4aa6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c8e0e-206a-7072-9dc4-83020c79e84f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 139, 'output_tokens': 12, 'total_tokens': 151})"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({'messages':[HumanMessage(content=\"What's my name?\")],\"language\":\"Hindi\"},\n",
    "                            config=config4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Managing The conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=lambda msgs: sum(len(m.content.split()) for m in msgs),\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"You're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi, I am Krish\"),\n",
    "    AIMessage(content=\"Hello Krish! How can I help you today?\"),\n",
    "    HumanMessage(content=\"Can you explain Newton's laws?\"), \n",
    "    AIMessage(content=\"Sure! Newton's laws describe the relationship between the motion of an object and the forces acting on it.\"),\n",
    "    HumanMessage(content=\"How do I make a perfect omelette?\"), \n",
    "    AIMessage(content=\"To make a perfect omelette, whisk eggs thoroughly, use medium heat, and fold gently when cooking.\"),\n",
    "    HumanMessage(content=\"What's the best workout for abs?\"), \n",
    "    AIMessage(content=\"Some of the best ab workouts include planks, bicycle crunches, and leg raises.\"),\n",
    "    HumanMessage(content=\"Which places should I visit in Paris?\"), \n",
    "     AIMessage(content=\"You should definitely see the Eiffel Tower, Louvre Museum, Notre-Dame, and Montmartre.\"),\n",
    "    HumanMessage(content=\"Translate 'Good morning' to French.\"), AIMessage(content=\"'Good morning' in French is 'Bonjour'.\"),\n",
    "    HumanMessage(content=\"Can you recommend some sci-fi movies?\"), AIMessage(content=\"Sure! Try 'Interstellar', 'The Matrix', 'Blade Runner 2049', and 'Inception'.\"),\n",
    "    HumanMessage(content=\"How should I save money for retirement?\"), AIMessage(content=\"Start by creating a budget, contribute to retirement accounts like 401(k) or IRA, and invest wisely.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What's the best workout for abs?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Some of the best ab workouts include planks, bicycle crunches, and leg raises.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='Which places should I visit in Paris?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='You should definitely see the Eiffel Tower, Louvre Museum, Notre-Dame, and Montmartre.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content=\"Translate 'Good morning' to French.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"'Good morning' in French is 'Bonjour'.\", additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='Can you recommend some sci-fi movies?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Sure! Try 'Interstellar', 'The Matrix', 'Blade Runner 2049', and 'Inception'.\", additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='How should I save money for retirement?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=80,  # <-- enough to keep sci-fi message\n",
    "    strategy=\"last\",\n",
    "    token_counter=lambda msgs: sum(len(m.content.split()) for m in msgs), # A function to count tokens (len is simple, or use model tokenizer)\n",
    "    start_on=\"human\",\n",
    "    end_on=(\"human\", \"tool\"),\n",
    ")\n",
    "\n",
    "# Your full conversation history\n",
    "messages=[\n",
    "    SystemMessage(content=\"You're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi, I am Krish\"),\n",
    "    AIMessage(content=\"Hello Krish! How can I help you today?\"),\n",
    "    HumanMessage(content=\"Can you explain Newton's laws?\"), \n",
    "    AIMessage(content=\"Sure! Newton's laws describe the relationship between the motion of an object and the forces acting on it.\"),\n",
    "    HumanMessage(content=\"How do I make a perfect omelette?\"), \n",
    "    AIMessage(content=\"To make a perfect omelette, whisk eggs thoroughly, use medium heat, and fold gently when cooking.\"),\n",
    "    HumanMessage(content=\"What's the best workout for abs?\"), \n",
    "    AIMessage(content=\"Some of the best ab workouts include planks, bicycle crunches, and leg raises.\"),\n",
    "    HumanMessage(content=\"Which places should I visit in Paris?\"), \n",
    "     AIMessage(content=\"You should definitely see the Eiffel Tower, Louvre Museum, Notre-Dame, and Montmartre.\"),\n",
    "    HumanMessage(content=\"Translate 'Good morning' to French.\"), AIMessage(content=\"'Good morning' in French is 'Bonjour'.\"),\n",
    "    HumanMessage(content=\"Can you recommend some sci-fi movies?\"), AIMessage(content=\"Sure! Try 'Interstellar', 'The Matrix', 'Blade Runner 2049', and 'Inception'.\"),\n",
    "    HumanMessage(content=\"How should I save money for retirement?\"), AIMessage(content=\"Start by creating a budget, contribute to retirement accounts like 401(k) or IRA, and invest wisely.\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Invoke the trimmer\n",
    "trimmed_messages = trimmer.invoke(messages)\n",
    "trimmed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked for Sci-Fi movies.'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain4=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt|model\n",
    ")\n",
    "response=chain4.invoke(\n",
    "    {\n",
    "    \"messages\":messages+[HumanMessage(content=\"What genre movies i asked you\")],\n",
    "    \"language\":\"English\"\n",
    "\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap in the Message History\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain4,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config5={\"configurable\":{\"session_id\":\"chat7\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke({'messages':[HumanMessage(content=\"What's my name?\")],\"language\":\"English\"},\n",
    "                            config=config5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't mention your name in our conversation so far. If you'd like to introduce yourself, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke({'messages':[HumanMessage(content=\"which country places I asked you to visit\")],\"language\":\"English\"},\n",
    "                            config=config5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't mention any countries or places that you'd like to visit in our conversation so far. If you'd like to discuss travel or plan a trip, I'd be happy to help!\""
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
